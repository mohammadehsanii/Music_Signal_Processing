# ğŸ§ Music Emotion Detection
*â€œWhere AI meets art to understand what music feels like.â€*

---

## ğŸ§  Project Summary

This project presents a **full-stack pipeline** for analyzing and predicting the **emotional attributes of music** based on their acoustic features. The system integrates:

- **Deep Learning** for classification  
- **MATLAB MIRtoolbox** for advanced audio feature extraction  
- **Flask Web App** for user interaction

Together, these components form a cohesive pipeline from raw audio input to emotion prediction output.

---

## âš™ï¸ System Architecture

```
ğŸµ Audio File (.mp3/.wav)
        â†“
ğŸ”¬ MATLAB Feature Extraction (MIRtoolbox)
        â†“
ğŸ“Š Python Preprocessing (scaler + label encoder)
        â†“
ğŸ¤– Emotion Prediction (Trained Neural Network)
        â†“
ğŸŒ Web Interface (Upload + Result Display)
```

---

## ğŸ“‚ Component Breakdown

### ğŸ”¬ 1. Feature Extraction with MATLAB

**Script:** `extract_features.m`  
**Toolbox Used:** [MIRtoolbox](https://www.jyu.fi/hytk/fi/laitokset/mutku/en/research/materials/mirtoolbox)

#### Key Features Extracted:
- **Temporal:** RMS energy, tempo, attack time, zero-crossing rate  
- **Spectral:** Centroid, spread, skewness, flatness, entropy, rolloff  
- **Perceptual:** Brightness, roughness, pulse clarity  
- **MFCCs:** 13 Mel-frequency cepstral coefficients  
- **Chromagram:** 12 pitch class intensities  
- **Harmonic Change Detection Function (HCDF)** stats

> Extracted features are saved as a CSV file (`extracted_features.csv`) for downstream prediction.

#### Highlights:
- Converts stereo to mono
- Polynomial slope analysis for fluctuation, roughness, and attack time
- Descriptive error handling for robust processing

---

### ğŸ§  2. Deep Learning Model in Python

**Notebook:** `Music_Emotion_Detection.ipynb`  
**Frameworks Used:** TensorFlow/Keras, scikit-learn

#### Process Flow:
1. **Data Cleaning & Preprocessing:**
   - Removes duplicates
   - Drops irrelevant HCDF periodic features
   - Encodes labels with `LabelEncoder`
   - Normalizes input with `StandardScaler`

2. **EDA & Visualization:**
   - Pie chart for class distribution
   - Correlation heatmap
   - Histograms for key features

3. **Model Architecture:**
   - **3 Dense Layers**: With BatchNorm, Dropout, LeakyReLU, L2 regularization
   - **Output Layer**: Softmax for multi-class emotion classification
   - **Optimizer**: Adam with learning rate `0.001`
   - **Callbacks**: EarlyStopping to prevent overfitting

4. **Evaluation:**
   - Accuracy score
   - Training/validation curve plots
   - Confusion matrix heatmap
   - Full classification report (Precision, Recall, F1)

#### Exported Files:
- `music_emotion_model.h5` â€“ Trained model
- `scaler.joblib` â€“ Feature standardizer
- `LabelEncoder.joblib` â€“ Class label encoder

---

### ğŸŒ 3. Web Interface using Flask

**Pages:**  
- ğŸ“¤ `upload.html` â€“ Music file upload interface  
- ğŸ¯ `result.html` â€“ Emotion prediction display  

#### Upload Interface:
- Beautiful gradient background  
- Intuitive drag-and-drop design  
- Accepts `.mp3`, `.wav`, `.flac`, `.ogg`

#### Result Page:
- Bold emotion label display  
- Stylized confirmation card  
- CTA to â€œUpload Another Songâ€

> The backend triggers MATLAB to extract features, loads the trained model and preprocessing tools, predicts emotion, and renders results dynamically.

---

## ğŸ“Š Sample Output

- ğŸµ **Input Audio**: `happy_guitar.wav`
- ğŸ“ˆ **Extracted Features**: 46 values
- ğŸ¤– **Predicted Emotion**: `Joy`

---

## âœ… Strengths

- ğŸ”„ **End-to-end Automation**: From upload to output in one click  
- ğŸ¼ **Rich Feature Set**: Leveraging advanced MIR descriptors  
- ğŸ“‰ **Robust Modeling**: Uses regularization, normalization, and early stopping  
- ğŸ’» **User-Friendly UI**: Beautiful and functional design  

---

## âš ï¸ Limitations

| Area             | Issue                                                                 |
|------------------|-----------------------------------------------------------------------|
| Feature Extraction | MATLAB dependency limits portability                               |
| Error Handling     | Flask backend can improve user feedback on exceptions              |
| Modeling           | No hyperparameter optimization or model tuning (yet)               |
| Deployment         | Not containerized; setup might be complex for new users            |

---

## ğŸš€ Future Improvements

1. ğŸ”„ Replace MATLAB with `librosa` or `pyAudioAnalysis` for better portability  
2. ğŸ”¬ Hyperparameter tuning (e.g., GridSearch, Bayesian Optimization)  
3. ğŸ“¦ Dockerize entire project for easy deployment  
4. ğŸ“± Make UI responsive and mobile-friendly  
5. ğŸ§  Experiment with CNNs or LSTM models for sequential audio inputs

---

## ğŸ“ Project Structure

```
ğŸ“¦ MusicEmotionAnalysis/
â”œâ”€â”€ ğŸ“ templates/
â”‚   â”œâ”€â”€ upload.html
â”‚   â””â”€â”€ result.html
â”œâ”€â”€ ğŸ§  Music_Emotion_Detection.ipynb
â”œâ”€â”€ ğŸ“œ extract_features.m
â”œâ”€â”€ ğŸ¤– music_emotion_model.h5
â”œâ”€â”€ ğŸ§® scaler.joblib
â”œâ”€â”€ ğŸ· LabelEncoder.joblib
â”œâ”€â”€ ğŸ”§ app.py (Flask App)
â””â”€â”€ ğŸ“„ README.md
```

---

## ğŸ’¬ Conclusion

This project captures the emotional fingerprint of music using a smart combination of signal processing, deep learning, and web tech. With a little refinement, it has potential not just for academia but for commercial music classification tools, therapy apps, and interactive experiences.

> _â€œThis is not just code â€“ it's the bridge between math and music.â€_
